services:
  init_nuclio:
    image: alpine:3.18
    command:
      - "/bin/sh"
      - "-c"
      - |
        mkdir -p /etc/nuclio/config/platform; \
        cat << EOF | tee /etc/nuclio/config/platform/platform.yaml
        runtime:
          common:
            env:
              MLRUN_DBPATH: http://${HOST_IP:?err}:8080
        local:
          defaultFunctionContainerNetworkName: mlrun
          defaultFunctionRestartPolicy:
            name: always
            maxRetryCount: 0
          defaultFunctionVolumes:
            - volume:
                name: mlrun-stuff
                hostPath:
                  path: ${SHARED_DIR:?err}
              volumeMount:
                name: mlrun-stuff
                mountPath: /home/jovyan/data/
        logger:
          sinks:
            myStdoutLoggerSink:
              kind: stdout
          system:
            - level: debug
              sink: myStdoutLoggerSink
          functions:
            - level: debug
              sink: myStdoutLoggerSink
        EOF
    volumes:
      - nuclio-platform-config:/etc/nuclio/config

  jupyter:
    image: "mlrun/jupyter:${TAG:-1.6.2}"
    ports:
      #- "8080:8080"
      - "8888:8888"
    environment:
      MLRUN_ARTIFACT_PATH: "/home/jovyan/data/{{project}}"
      MLRUN_LOG_LEVEL: DEBUG
      MLRUN_NUCLIO_DASHBOARD_URL: http://nuclio:8070
      MLRUN_HTTPDB__DSN: "sqlite:////home/jovyan/data/mlrun.db?check_same_thread=false"
      MLRUN_UI__URL: http://localhost:8060
      # using local storage, meaning files / artifacts are stored locally, so we want to allow access to them
      MLRUN_HTTPDB__REAL_PATH: "/home/jovyan/data"
      # not running on k8s meaning no need to store secrets
      MLRUN_SECRET_STORES__KUBERNETES__AUTO_ADD_PROJECT_SECRETS: "false"
      # let mlrun control nuclio resources
      MLRUN_HTTPDB__PROJECTS__FOLLOWERS: "nuclio"
    volumes:
      - "${SHARED_DIR:?err}:/home/jovyan/data"
    networks:
      - mlrun

  mlrun-api:
    image: "mlrun/mlrun-api:${TAG:-1.6.2}"
    ports:
      - "8080:8080"
    environment:
      S3_ENDPOINT_URL: "minio:9000"
      AWS_ACCESS_KEY_ID: "lwycuW6S5f7yJZt65tRK"
      AWS_SECRET_ACCESS_KEY: "d6hXquiXGpbmfR8OdX7Byd716hmhN87xTyCX8S0K"
      MLRUN_STORAGE__AUTO_MOUNT_TYPE: s3
      MLRUN_STORAGE__AUTO_MOUNT_PARAMS: "aws_access_key=lwycuW6S5f7yJZt65tRK,aws_secret_key=d6hXquiXGpbmfR8OdX7Byd716hmhN87xTyCX8S0K,endpoint_url=minio:9000"
      MLRUN_HTTPDB__REAL_PATH: s3://
      MLRUN_ARTIFACT_PATH: s3://mlrun/projects/{{ `{{run.project}}` }}/artifacts
      MLRUN_FEATURE_STORE__DATA_PREFIXES__DEFAULT: s3://mlrun/projects/{project}/FeatureStore/{name}/{kind}

      #MLRUN_ARTIFACT_PATH: "${SHARED_DIR}/{{project}}"
      # using local storage, meaning files / artifacts are stored locally, so we want to allow access to them
      #MLRUN_HTTPDB__REAL_PATH: /data
      MLRUN_HTTPDB__DATA_VOLUME: "${SHARED_DIR}"
      MLRUN_LOG_LEVEL: DEBUG
      MLRUN_NUCLIO_DASHBOARD_URL: http://nuclio:8070
      MLRUN_HTTPDB__DSN: "sqlite:////data/mlrun.db?check_same_thread=false"
      MLRUN_UI__URL: http://localhost:8060
      # not running on k8s meaning no need to store secrets
      MLRUN_SECRET_STORES__KUBERNETES__AUTO_ADD_PROJECT_SECRETS: "false"
      # let mlrun control nuclio resources
      MLRUN_HTTPDB__PROJECTS__FOLLOWERS: "nuclio"
    volumes:
      - "${SHARED_DIR:?err}:/data"
    networks:
      - mlrun

  mlrun-ui:
    image: "mlrun/mlrun-ui:${TAG:-1.6.2}"
    ports:
      - "8060:8090"
    environment:
      MLRUN_API_PROXY_URL: http://mlrun-api:8080
      MLRUN_NUCLIO_MODE: enable
      MLRUN_NUCLIO_API_URL: http://nuclio:8070
      MLRUN_NUCLIO_UI_URL: http://localhost:8070
    networks:
      - mlrun

  nuclio:
    image: "quay.io/nuclio/dashboard:${NUCLIO_TAG:-stable-amd64}"
    ports:
      - "8070:8070"
    environment:
      NUCLIO_DASHBOARD_EXTERNAL_IP_ADDRESSES: "${HOST_IP:?err}"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - nuclio-platform-config:/etc/nuclio/config
    depends_on:
      - init_nuclio
    networks:
      - mlrun

  minio:
    image: quay.io/minio/minio
    #network_mode: "host"
    volumes:
      #- /d/data:/data
      #- ./data:/data
      - ~/minio-data:/data
    ports:
      - 9000:9000
      - 9001:9001
    #extra_hosts:
    #  - "host.docker.internal:host-gateway"
    environment:
      MINIO_ROOT_USER: 'minio_user'
      MINIO_ROOT_PASSWORD: 'minio_password'
      MINIO_ADDRESS: ':9000'
      MINIO_STORAGE_USE_HTTPS: False
      MINIO_CONSOLE_ADDRESS: ':9001'
      #MINIO_LAMBDA_WEBHOOK_ENABLE_function: 'on'
      #MINIO_LAMBDA_WEBHOOK_ENDPOINT_function: 'http://localhost:5000'
    command: minio server /data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - mlrun
    
volumes:
  nuclio-platform-config: {}

networks:
  mlrun:
    name: mlrun